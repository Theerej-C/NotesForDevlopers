* Every time we run terraform it records the infrastructure info in a `Terraform state file`. 
* By default, when you run Terraform in the folder /foo/bar, Terraform creates the file /foo/bar/terraform.tfstate. This file contains a custom JSON format that records a mapping from the Terraform resources in your configuration files to the representation of those resources in the real world.
* The `terraform plan` output is the diff between the code and the real world infrastructure like the AWS.
* If it is for personal project then the single state file is no problem but if we work as a team there are problems arise when there is single terraform file.
* We need Shared Storage for state files, Locking state files for concurrency, Isolating State files.
* In this case we cannot rely on VCS for the storage and sharing so there is a mechanism in the Terraform named `backend`. Entire time we had done the local backend but there are `Remote backend` allow us to store the file in remote.
* AWS S3 is an excellent backend for the storage and sharing where we can define it easily in terraform itself.
* First we need to create a S3 bucket in the AWS. IT should be in diff folder than the last file.
* We set the `bucket` property uniquely as it is globally recognized. Then add the `prevent_destroy` to true.
* Next we need to set the versioning to be enabled so that we can revert back to the previous version. Like:
```
resource "aws_s3_bucket_versioning" "enabled" {
  bucket = aws_s3_bucket.state.id
  versioning_configuration {
    status = "Enabled"
  }
}
```
* Next use the `aws_server_side_encryption` which will turn server-side encryption on by default. Like:
```
resource "aws_s3_bucket_server_side_encryption_configuration" "default" {
    bucket = aws_s3_bucket.state.id
    rule {
      apply_server_side_encryption_by_default {
        sse_algorithm = "AES256"
      }
    }
}
```
* Then set the resource of S3 to be publicly blocked so that it is private:
```

```