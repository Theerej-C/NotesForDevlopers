* Every time we run terraform it records the infrastructure info in a `Terraform state file`. 
* By default, when you run Terraform in the folder /foo/bar, Terraform creates the file /foo/bar/terraform.tfstate. This file contains a custom JSON format that records a mapping from the Terraform resources in your configuration files to the representation of those resources in the real world.
* The `terraform plan` output is the diff between the code and the real world infrastructure like the AWS.
* If it is for personal project then the single state file is no problem but if we work as a team there are problems arise when there is single terraform file.
* We need Shared Storage for state files, Locking state files for concurrency, Isolating State files.
* In this case we cannot rely on VCS for the storage and sharing so there is a mechanism in the Terraform named `backend`. Entire time we had done the local backend but there are `Remote backend` allow us to store the file in remote.
* AWS S3 is an excellent backend for the storage and sharing where we can define it easily in terraform itself.
* First we need to create a S3 bucket in the AWS. IT should be in diff folder than the last file.
* We set the `bucket` property uniquely as it is globally recognized. Then add the `prevent_destroy` to true.
* Next we need to set the versioning to be enabled so that we can revert back to the previous version. Like:
```
resource "aws_s3_bucket_versioning" "enabled" {
  bucket = aws_s3_bucket.state.id
  versioning_configuration {
    status = "Enabled"
  }
}
```
* Next use the `aws_server_side_encryption` which will turn server-side encryption on by default. Like:
```
resource "aws_s3_bucket_server_side_encryption_configuration" "default" {
    bucket = aws_s3_bucket.state.id
    rule {
      apply_server_side_encryption_by_default {
        sse_algorithm = "AES256"
      }
    }
}
```
* Then set the resource of S3 to be publicly blocked so that it is private:
```
resource "aws_s3_bucket_public_access_block" "public_access" {
  bucket                  = aws_s3_bucket.state.id
  block_public_acls       = true
  block_public_policy     = true
  ignore_public_acls      = true
  restrict_public_buckets = true
}
```
* Then we need to create a dynamo db for the consistency or the locking of operations. It is a key value store where we can store the key value pairs.
```
resource "aws_dynamodb_table" "terraform_lock" {
  name         = "terraform-up-ex"
  billing_mode = "PAY_PER_REQUEST"
  hash_key     = "LockID"
  attribute {
    name = "LockID"
    type = "S"
  }
}
```
* So as this is created we need to set the backend to store the state file in this S3 bucket so that it will be available to the team.
* It has to be done in the `terraform` block with the `backend` and the configuration.
```
terraform {
  backend "s3" {
    bucket = "terraform-state-ex"
    key = "global/s3/terraform.tfstate"
    region = "us-east-1"

    dynamodb_table = "terraform-up-ex"
    encrypt = true
  }
}
```
* Here the key is the place in the S3 where we need to store the state file. To work this config has to be initialised again using the `init`.
* There are some limitations in the backend of the Terraform:
  * The first limitation is that we have a egg-chicken-egg situation where the dynamo DB and the S3 will depend on each other so there will be problem in the deleting or removing them.
  * Then the next one is the most notorious where we cannot use the variables inside the backend so we need to copy and paste the names.
* We can have a backend config hcl file and to run it `terraform init --backend-config FILENAME` to use the file name so that we can use the references of the variables.
* Terragrunt is an open source tool which can helpus in these kinds of situations.
## State File Isolation(Workspace Isolation):
* As we are doing like configure using only single file or state file it will become messier. So we need isolation for the scalability.
* We can have two types of state file isolation:
  * Isolation via workspaces
  * Isolation via file layout.
* `Terraform Workspaces` will allow us to have a different workspaces in the Terraform.
* The `terraform workspace show` will show what is the workspace is been used. The default one is the `default`.
* We can create a new workspace using the `terraform workspace new NAME`. 
* So after changing the workspace if we try to run any commands it will create a new instance using the same file as the state file of the each workspace is separate.
* We can use the `terraform workspace list` to list the worspaces and the `terraform workspace select NAME` to select the specific workspace.
* Switching to a different workspace is equivalent to changing the path where your state file is stored.
* We can use the ternary syntax to select which is the packe where the configuration should set.
```
resource "aws_instance" "ex11"{
  ami                         = "ami-0fb653ca2d3203ac1"
  instance_type = terraform.workspace == "default" ? "t2.medium":"t2.micro"
}
```
* But the workspaces have some disadvantages like:
  * The state files are stored in the same backend so we use the same authentication and access control.
  * As workspaces are not seen in the code as it is just a terminal command which is opposite to the IaS.
  * So we use same file to do something which is totally error prone.
## File Isolation: 
* So we need to do another or for complete isolation is that :
  * Put terraform config files for each environment into a seperate folder.
  * Configure a different backend for each environment and different authentication like different for staging and production.
* So we can have a good common dir structure like seperate things like:
  * Stage: Pre production workloads.
  * Prod: An environment fo production workloads.
  * mgmt: An environment for DevOps tooling like baston host, CI server.
  * global: A place to put the resources that are used across all environments.
* Within each of the envs there are some seperate folders for the components which differes from project to project.
  * vpc: network topology for env
  * services: The apps microservices to run in the envs.
  * data-storage: The data stores to run in the environment.
* Within each of the component there are actual config files like variables.tf, outputs.tf, main.tf.