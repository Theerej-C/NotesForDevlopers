* The first thing to do is to have the authentication key and the access key from the cloud providers like AWS, azure, etc. 
* For example in AWS the names are AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY has to be set as an environment variable in the system we work on.
* The configuration file will be written in the HCL (HashiCorp Configuration Language) which has a extension of .tf.
* It is a declarative language, so your goal is to describe the infrastructure you want, and Terraform will figure out how to create it.
* The syntax for the .tf file is pretty simple where we can decide the cloud provider in outside of the block and the configuration inside the block.
* The example is 
```
resource "<PROVIDER>_<TYPE>" "<NAME>" {
[CONFIG ...]
}
Eg: 
provider "aws" {

region = "ap-south-1"

}
```
* This invokes a single server in the AWS with the Region of the ap-south-1. 
* As the AWS free account itself required a credit or debit card we need to use the emulators like localstack. 
* The localstack provides functionalities of the AWS cloud in local machine so that we can use that to test the environment of the AWS in the local machine and then we can host it in the actual AWS.
* First we need to install the local stack cli with the command `brew install localstack/tap/localstack-cli` which will install the local stack cli and then we need to execute the command `localstack start` to start the local stack where the port is 4566.
* Then we can use the AWS cli to access the end point and do operations on the virtual AWS local cloud. For example to list the s3 buckets `aws --no-sign-request --endpoint-url=http://localhost:4566 s3 ls`.
* The --no-sign-request is for the skip of AWS credentials in the local stack and the endpoint is the localstack endpoint. But when we want to use the real AWS the AWS environment variables like:
```
export AWS_ACCESS_KEY_ID=AKIAIOSFODNN7EXAMPLE
export AWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
export AWS_DEFAULT_REGION=us-west-2
```
* Then we can use any code editor to create a terraform file(.tf) which can be run using commands. But we need to be careful in setting up the configuration for the localstack because as we emulate the cloud we need to skip some credentials in the provider section like:
```
provider "aws" {
    region = "us-east-1"
    access_key = "test123"
    secret_key = "test"
    skip_credentials_validation = true
    skip_requesting_account_id = true
    skip_metadata_api_check = true
    s3_use_path_style = true
    endpoints {
      s3 = "http://localhost:4566"
    }
}
resource "aws_s3_bucket" "b" {
    bucket = "theerej"
}
```
* The s3 bucket is the example here but we need different options to be enabled for different services in the cloud.
* The `terraform init` is for initialising the folder for the terraform functionalities. Then we can use the `terraform plan` to see what are the changes that are going to happen when we apply the changes.
* Then we can use the `terraform apply` to apply the changes in the infrastructure.
* The output will be like:
![[Pasted image 20240307104238.png]]
* So when we edit the same configuration file the terraform will delete the existing resource and create the new one with the configuration we changed like when we add a tag name for already create t2\.micro instance then it will crate a new. 
### Deploying Server:
* So when the infrastructure has been created we can deploy servers, Databases, etc inside the infrastructure. 
* For this example used a dirt server where in real life we will build servers with python django, etc frameworks.
* So to run the server we need to usually use some server templating tools like packer to create a custom ami but this is a one liner so we can just paste the script in the `user_data` section in the resource part.
```
user_data = <<-EOF
            #!/bin/bash
            echo "Hello, World" > index.xhtml
            nohup busybox httpd -f -p 8080 &
            EOF
user_data_replace_on_change = true
```
* The <<-EOF and EOF are Terraformâ€™s heredoc syntax, which allows you to create multi line strings without having to insert \n characters all over the place.
* user_data_replace_on_change is to replace the existing instance and replace with the script.
* But before this webserver working we need a AWS security group for the access so we need to create a security group with the resource like:
```
resource "aws_security_group" "instance" {
  name = "terraform-example-instance"
  ingress {
    from_port   = 8080
    to_port     = 8080
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }
}
```
* Here the CIDR bloack specifies any IP range so that any request can comes in.
* We need to pass in the id of the security group to the EC2 instance so that we can have a definition.
* To access ID if the security group we can use the *reference* syntax of the terraform. Like `<PROVIDER>_<TYPE>.<NAME>.<ATTRIBUTE>`. Eg: `aws_security_group.instance.id`
* When you add a reference from one resource to another, you create an implicit dependency. Terraform parses this and build a dependency graph which can be viewed by `terraform graph`.
* The output is in a graph description language called DOT, which you can turn into an image, similar to the dependency graph shown in by using a desktop app such as Graphviz or web app like GraphvizOnline
* ![[Pasted image 20240307115725.png]]
* 