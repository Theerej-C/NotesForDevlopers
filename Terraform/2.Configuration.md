* The first thing to do is to have the authentication key and the access key from the cloud providers like AWS, azure, etc. 
* For example in AWS the names are AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY has to be set as an environment variable in the system we work on.
* The configuration file will be written in the HCL (HashiCorp Configuration Language) which has a extension of .tf.
* It is a declarative language, so your goal is to describe the infrastructure you want, and Terraform will figure out how to create it.
* The syntax for the .tf file is pretty simple where we can decide the cloud provider in outside of the block and the configuration inside the block.
* The example is 
```
resource "<PROVIDER>_<TYPE>" "<NAME>" {
[CONFIG ...]
}
Eg: 
provider "aws" {

region = "ap-south-1"

}
```
* This invokes a single server in the AWS with the Region of the ap-south-1. 
* As the AWS free account itself required a credit or debit card we need to use the emulators like localstack. 
* The localstack provides functionalities of the AWS cloud in local machine so that we can use that to test the environment of the AWS in the local machine and then we can host it in the actual AWS.
* First we need to install the local stack cli with the command `brew install localstack/tap/localstack-cli` which will install the local stack cli and then we need to execute the command `localstack start` to start the local stack where the port is 4566.
* Then we can use the AWS cli to access the end point and do operations on the virtual AWS local cloud. For example to list the s3 buckets `aws --no-sign-request --endpoint-url=http://localhost:4566 s3 ls`.
* The --no-sign-request is for the skip of AWS credentials in the local stack and the endpoint is the localstack endpoint. But when we want to use the real AWS the AWS environment variables like:
```
export AWS_ACCESS_KEY_ID=AKIAIOSFODNN7EXAMPLE
export AWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
export AWS_DEFAULT_REGION=us-west-2
```
* Then we can use any code editor to create a terraform file(.tf) which can be run using commands. But we need to be careful in setting up the configuration for the localstack because as we emulate the cloud we need to skip some credentials in the provider section like:
```
provider "aws" {
    region = "us-east-1"
    access_key = "test123"
    secret_key = "test"
    skip_credentials_validation = true
    skip_requesting_account_id = true
    skip_metadata_api_check = true
    s3_use_path_style = true
    endpoints {
      s3 = "http://localhost:4566"
    }
}
resource "aws_s3_bucket" "b" {
    bucket = "theerej"
}
```
* The s3 bucket is the example here but we need different options to be enabled for different services in the cloud.
* The `terraform init` is for initialising the folder for the terraform functionalities. Then we can use the `terraform plan` to see what are the changes that are going to happen when we apply the changes.
* Then we can use the `terraform apply` to apply the changes in the infrastructure.
* The output will be like:
![[Pasted image 20240307104238.png]]
* So when we edit the same configuration file the terraform will delete the existing resource and create the new one with the configuration we changed like when we add a tag name for already create t2\.micro instance then it will crate a new. 