* Every time we run terraform it records the infrastructure info in a `Terraform state file`. 
* By default, when you run Terraform in the folder /foo/bar, Terraform creates the file /foo/bar/terraform.tfstate. This file contains a custom JSON format that records a mapping from the Terraform resources in your configuration files to the representation of those resources in the real world.
* The `terraform plan` output is the diff between the code and the real world infrastructure like the AWS.
* If it is for personal project then the single state file is no problem but if we work as a team there are problems arise when there is single terraform file.
* We need Shared Storage for state files, Locking state files for concurrency, Isolating State files.
* In this case we cannot rely on VCS for the storage and sharing so there is a mechanism in the Terraform named `backend`. Entire time we had done the local backend but there are `Remote backend` allow us to store the file in remote.
* AWS S3 is an excellent backend for the storage and sharing where we can define it easily in terraform itself.
* First we need to create a S3 bucket in the AWS. IT should be in diff folder than the last file.
* We set the `bucket` property uniquely as it is globally recognized. Then add the `prevent_destroy` to true.
* Next we need to set the versioning to be enabled so that we can revert back to the previous version. Like:
```
resource "aws_s3_bucket_versioning" "enabled" {
  bucket = aws_s3_bucket.state.id
  versioning_configuration {
    status = "Enabled"
  }
}
```
* Next use the `aws_server_side_encryption` which will turn server-side encryption on by default. Like:
```
resource "aws_s3_bucket_server_side_encryption_configuration" "default" {
    bucket = aws_s3_bucket.state.id
    rule {
      apply_server_side_encryption_by_default {
        sse_algorithm = "AES256"
      }
    }
}
```
* Then set the resource of S3 to be publicly blocked so that it is private:
```
resource "aws_s3_bucket_public_access_block" "public_access" {
  bucket                  = aws_s3_bucket.state.id
  block_public_acls       = true
  block_public_policy     = true
  ignore_public_acls      = true
  restrict_public_buckets = true
}
```
* Then we need to create a dynamo db for the consistency or the locking of operations. It is a key value store where we can store the key value pairs.
```
resource "aws_dynamodb_table" "terraform_lock" {
  name         = "terraform-up-ex"
  billing_mode = "PAY_PER_REQUEST"
  hash_key     = "LockID"
  attribute {
    name = "LockID"
    type = "S"
  }
}
```
* So as this is created we need to set the backend to store the state file in this S3 bucket so that it will be available to the team.
* It has to be done in the `terraform` block with the `backend` and the configuration.
```
terraform {
  backend "s3" {
    bucket = "terraform-state-ex"
    key = "global/s3/terraform.tfstate"
    region = "us-east-1"

    dynamodb_table = "terraform-up-ex"
    encrypt = true
  }
}
```
* Here the key is the place in the S3 where we need to store the state file. To work this config has to be initialised again using the `init`.
* 